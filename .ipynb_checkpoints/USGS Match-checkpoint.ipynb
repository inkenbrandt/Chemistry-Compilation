{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import shutil\n",
    "import urllib2\n",
    "from urllib2 import urlopen\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as tick\n",
    "import scipy.stats as sp\n",
    "import statsmodels.api as sm\n",
    "from pandas.stats.api import ols\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from pylab import rcParams\n",
    "import platform\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import urllib\n",
    "import HTMLParser\n",
    "from cStringIO import StringIO\n",
    "\n",
    "import pyproj\n",
    "from pyproj import Proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wellapplication as wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System Windows 7\n",
      "Python Version 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\n",
      "Pandas Version 0.18.1\n",
      "Numpy Version 1.11.0\n",
      "Well Application Version 0.2.13\n"
     ]
    }
   ],
   "source": [
    "print(\"Operating System \" + platform.system() + \" \" + platform.release())\n",
    "print(\"Python Version \" + str(sys.version))\n",
    "print(\"Pandas Version \" + str(pd.__version__))\n",
    "print(\"Numpy Version \" + str(np.__version__))\n",
    "print(\"Well Application Version \" + str(wa.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engineroute = \"H:/Google Drive/WORK/Groundwater Chemistry\"\n",
    "#engineroute = \"C:/Users/Brooke/Downloads/\"\n",
    "sys.path.append(engineroute)\n",
    "import enginegetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = enginegetter.getEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Locate ArcPy and add it to the path\n",
    "Created on 13 Feb 2015\n",
    "@author: Jamesramm\n",
    "https://github.com/JamesRamm/archook/blob/master/archook.py\n",
    "'''\n",
    "import _winreg\n",
    "import sys\n",
    "from os import path\n",
    "def locate_arcgis():\n",
    "  '''\n",
    "  Find the path to the ArcGIS Desktop installation.\n",
    "  Keys to check:\n",
    "  HLKM/SOFTWARE/ESRI/ArcGIS 'RealVersion' - will give the version, then we can use\n",
    "  that to go to\n",
    "  HKLM/SOFTWARE/ESRI/DesktopXX.X 'InstallDir'. Where XX.X is the version\n",
    "  We may need to check HKLM/SOFTWARE/Wow6432Node/ESRI instead\n",
    "  '''\n",
    "  try:\n",
    "    key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                          'SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\ArcGIS', 0)\n",
    "\n",
    "    version = _winreg.QueryValueEx(key, \"RealVersion\")[0][:4]\n",
    "\n",
    "    key_string = \"SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\Desktop{0}\".format(version)\n",
    "    desktop_key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                                  key_string, 0)\n",
    "\n",
    "    install_dir = _winreg.QueryValueEx(desktop_key, \"InstallDir\")[0]\n",
    "    return install_dir\n",
    "  except WindowsError:\n",
    "    raise ImportError(\"Could not locate the ArcGIS directory on this machine\")\n",
    "\n",
    "def get_arcpy():  \n",
    "  '''\n",
    "  Allows arcpy to imported on 'unmanaged' python installations (i.e. python installations\n",
    "  arcgis is not aware of).\n",
    "  Gets the location of arcpy and related libs and adds it to sys.path\n",
    "  '''\n",
    "  install_dir = locate_arcgis()  \n",
    "  arcpy = path.join(install_dir, \"arcpy\")\n",
    "  # Check we have the arcpy directory.\n",
    "  if not path.exists(arcpy):\n",
    "    raise ImportError(\"Could not find arcpy directory in {0}\".format(install_dir))\n",
    "\n",
    "  # First check if we have a bin64 directory - this exists when arcgis is 64bit\n",
    "  bin_dir = path.join(install_dir, \"bin64\")\n",
    "  if not path.exists(bin_dir):\n",
    "    # Fall back to regular 'bin' dir otherwise.\n",
    "    bin_dir = path.join(install_dir, \"bin\")\n",
    "\n",
    "  scripts = path.join(install_dir, \"ArcToolbox\", \"Scripts\")  \n",
    "  sys.path.extend([arcpy, bin_dir, scripts])\n",
    "\n",
    "get_arcpy()\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = pd.read_excel(engineroute+\"/Stations.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources table built using data scraped from the Utah Division of Water Rights Website.  Match based on state designated number or name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systems = pd.read_sql_table('systems',con=engine)\n",
    "sources = pd.read_sql_table('sources',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(stations)):\n",
    "    syslist = systems[systems['pwsid'] == stations.ix[i,'ALTERNATE_ST_NUM']]['systemnum'].values\n",
    "    if len(syslist) > 0:\n",
    "        stations.ix[i,'systemnum'] = str(int(syslist[0])).zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources = sources[sources['source type'].isin(['Well','Spring'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources['systemnum'] = sources['source id'].apply(lambda x: x.split('-')[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sourceclean(x):\n",
    "    x = x.title()\n",
    "    x = x.replace('#','')\n",
    "    x = x.replace('No.','')\n",
    "    x = x.replace('No ','')\n",
    "    x = x.replace('Num ','')\n",
    "    x = x.replace('Well','')\n",
    "    x = x.replace('Spring','')\n",
    "    x = x.replace('Springs','')\n",
    "    x = x.replace('Sring','')\n",
    "    x = x.replace(' in','-in')\n",
    "    x = x.replace(' Inch','-in')\n",
    "    x = x.replace('-Inch','-in')\n",
    "    x = x.replace('\\'','-in')\n",
    "    x = x.replace('Inches','-in')\n",
    "    x = x.rstrip()\n",
    "    x = x.lstrip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources['simpSource'] = sources['source'].apply(lambda x: sourceclean(x),1)\n",
    "stations['simpSource'] = stations['UTV80_TINWSF_NAME'].apply(lambda x: sourceclean(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(stations)):\n",
    "    try:\n",
    "        matchstat =  str(int(stations.ix[i,'ALTERNATE_ST_NUM'])).zfill(5)\n",
    "        srclist = list(sources[sources['system id'] == matchstat]['source'].values)\n",
    "        shrtsrc = list(sources[sources['system id'] == matchstat]['short_source'].values)\n",
    "        winlist = list(sources[sources['system id'] == matchstat]['win'].values)\n",
    "        idlist = list(sources[sources['system id'] == matchstat]['source id'].values)\n",
    "        dehnlist = list(sources[sources['system id'] == matchstat]['DEHN source id'].values)\n",
    "        simpsrc =  list(sources[sources['system id'] == matchstat]['simpSource'].values)\n",
    "        if len(srclist) > 0:\n",
    "            for j in range(len(srclist)):\n",
    "                try:\n",
    "                    if str(stations.ix[i,'UTV80_TINWSF_NAME']).title() in srclist[j]:\n",
    "                        stations.ix[i,'win'] = winlist[j]\n",
    "                        stations.ix[i,'alt_name'] = srclist[j]\n",
    "                        stations.ix[i, 'sourceID'] = idlist[j]\n",
    "                    elif str(stations.ix[i,'UTV80_TINWSF_NAME']).title() in shrtsrc[j]:\n",
    "                        stations.ix[i,'win'] = winlist[j]\n",
    "                        stations.ix[i,'alt_name'] = srclist[j]\n",
    "                        stations.ix[i, 'sourceID'] = idlist[j]\n",
    "                    elif stations.ix[i,'simpSource'] in simpsrc[j]:\n",
    "                        stations.ix[i,'win'] = winlist[j]\n",
    "                        stations.ix[i,'alt_name'] = srclist[j]\n",
    "                        stations.ix[i, 'sourceID'] = idlist[j]\n",
    "                    elif len(dehnlist[j])>5 and (int(stations.ix[i,'ST_ASGN_IDENT_CD'][-3:]) == int(dehnlist[j][-2:])):\n",
    "                        stations.ix[i,'win'] = winlist[j]\n",
    "                        stations.ix[i,'alt_name'] = srclist[j]\n",
    "                        stations.ix[i, 'sourceID'] = idlist[j]\n",
    "                except(TypeError):\n",
    "                    pass\n",
    "    except(ValueError):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'C:/GIS/WR_RAW_FILES/'\n",
    "fileloc = r'C:/GIS/WR_DATA.gdb/'\n",
    "statloc = path + 'stations.csv'\n",
    "arcpy.env.workspace = fileloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delif(x):\n",
    "    if arcpy.Exists(x):\n",
    "        arcpy.Delete_management(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project SDWIS Stations into UTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def statproj(x):\n",
    "    ltd = x[0]\n",
    "    lng = x[1]\n",
    "    dat = x[2]\n",
    "    datdic = {1:'epsg:4267',2:'epsg:4269',3:'epsg:4326'}\n",
    "    p1 = Proj(init=datdic.get(x[2],'epsg:4269'))\n",
    "    p2 = Proj(proj='utm',zone=12,datum='NAD83')\n",
    "    if x[0] > 0 and abs(x[1]) > 0:\n",
    "        x1, y1 = pyproj.transform(p1, p2, lng, ltd)\n",
    "        return x1,y1\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "stations['UTMx'] = stations[[u'LATITUDE_MEASURE', u'LONGITUDE_MEASURE', u'HORIZ_REF_DATUM_CD']].apply(lambda x: statproj(x)[0],1)\n",
    "stations['UTMy'] = stations[[u'LATITUDE_MEASURE', u'LONGITUDE_MEASURE', u'HORIZ_REF_DATUM_CD']].apply(lambda x: statproj(x)[1],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframe into a gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df2csv2gdb(df,fileloc,csvloc,name,ind=False):\n",
    "    '''\n",
    "    converts dataframe to csv file to esri gdb\n",
    "    '''\n",
    "    df.to_csv(csvloc,index=ind)\n",
    "    if arcpy.Exists(fileloc + name):\n",
    "        arcpy.Delete_management(fileloc + name)\n",
    "        arcpy.TableToTable_conversion(csvloc, fileloc, name)\n",
    "    else:\n",
    "        arcpy.TableToTable_conversion(csvloc, fileloc, name)\n",
    "\n",
    "name='stations'\n",
    "df2csv2gdb(stations,fileloc,statloc,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert SDWIS station table into a point feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4217 points created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:/GIS/WR_DATA.gdb\\\\SDWIS_Stats'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the local variables\n",
    "in_Table = fileloc + 'stations'\n",
    "x_coords = 'UTMx'\n",
    "y_coords = 'UTMy'\n",
    "out_Layer = 'SDWISStats'\n",
    "stationname = 'SDWIS_Stats'\n",
    "saved_Layer = path + 'SDWIS_Stations.lyr'\n",
    "\n",
    "# Set the spatial reference\n",
    "spRef = r\"Coordinate Systems\\Projected Coordinate Systems\\Utm\\Nad 1983\\NAD 1983 UTM Zone 12N.prj\"\n",
    "\n",
    "# Make the XY event layer...\n",
    "delif(out_Layer)\n",
    "arcpy.MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, spRef)\n",
    "\n",
    "# Print the total rows\n",
    "print(str(arcpy.GetCount_management(out_Layer))+ ' points created!')\n",
    "\n",
    "delif(fileloc + stationname)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(out_Layer, fileloc, stationname)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Water Rights Data to feature classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrpod\n",
      "muni\n"
     ]
    }
   ],
   "source": [
    "def extractfile(url, path):\n",
    "    '''\n",
    "    download and extracts zip file from internet\n",
    "    replaces file if it already exists\n",
    "    returns name of subdirectory in the given path\n",
    "    '''\n",
    "    filename = urllib.urlretrieve(url)[0]\n",
    "    zipobject = zipfile.ZipFile(filename, 'r')\n",
    "    subdir = str(zipobject.namelist()[0]).split('.')[0]\n",
    "    try: \n",
    "        os.makedirs(path+subdir+'/')\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path+subdir+'/'):\n",
    "            raise\n",
    "        else:\n",
    "            shutil.rmtree(path+subdir+'/')\n",
    "            os.makedirs(path+subdir+'/')\n",
    "    zipobject.extractall(path+subdir+'/')\n",
    "    return subdir\n",
    "\n",
    "def urltogdb(url,path,fileloc):\n",
    "    name = extractfile(url,path)\n",
    "    delif(fileloc + name)\n",
    "    arcpy.CopyFeatures_management(path+name+'/'+name+'.shp', fileloc + name)\n",
    "    print(name)\n",
    "    return name\n",
    "        \n",
    "url = 'http://maps.waterrights.utah.gov/Downloads/wrpod.zip'   \n",
    "wrpod = urltogdb(url,path,fileloc)\n",
    "url = 'http://maps.waterrights.utah.gov/Downloads/wateruse.zip'\n",
    "muni = urltogdb(url,path,fileloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select subset of data with a query by attribute and then reproject to match stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "delif('lyr')\n",
    "arcpy.MakeFeatureLayer_management(wrpod, \"lyr\") \n",
    " \n",
    "query = \"WIN > 0 AND ( USES LIKE '%M%' OR OWNER  LIKE '%CITY%' OR OWNER LIKE '%TOWN%' OR OWNER LIKE '%SERVICE%' OR OWNER LIKE '%DISTRICT%' OR OWNER LIKE '%COUNTY%' OR OWNER LIKE '%UTAH%')\"\n",
    "# Within selected features, further select only those cities which have a population > 10,000   \n",
    "arcpy.SelectLayerByAttribute_management(\"lyr\", \"NEW_SELECTION\", query)\n",
    "\n",
    "delif('wrpod_win')\n",
    "# Write the selected features to a new featureclass\n",
    "arcpy.CopyFeatures_management(\"lyr\", \"wrpod_win\")\n",
    "\n",
    "outCS = arcpy.SpatialReference('NAD 1983 UTM Zone 12N')\n",
    "delif('wrpod_win_proj')\n",
    "arcpy.Project_management('wrpod_win', 'wrpod_win_proj', outCS)\n",
    "\n",
    "delif('muni_proj')\n",
    "arcpy.Project_management(muni, 'muni_proj', outCS)\n",
    "arcpy.Delete_management('wrpod_win')\n",
    "arcpy.Delete_management(muni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delif(stationname+'_wrpod')\n",
    "arcpy.SpatialJoin_analysis(stationname, 'wrpod_win_proj', stationname+'_wrpod', \"#\", \"#\",  \"#\",'WITHIN_A_DISTANCE',\"100 Meters\")\n",
    "arcpy.Delete_management(stationname)\n",
    "arcpy.SpatialJoin_analysis(stationname+'_wrpod', 'muni_proj', stationname+'joins', \"#\", \"#\",  \"#\",'WITHIN_A_DISTANCE',\"500 Meters\")\n",
    "arcpy.Delete_management(stationname+'_wrpod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "droplist = [u'Join_Count', u'TARGET_FID', u'Join_Count_1', u'TARGET_FID_1', u'LAT_DMS_MSR',\n",
    "            u'LONG_DMS_MSR', u'HZ_COLLECT_METH_CD', u'HORIZ_ACCURACY_MSR', u'HORIZ_REF_DATUM_CD',\n",
    "            u'SOURCE_MAP_SCALE', u'COORDINATE_DTA_SRC', u'VERTICAL_MEASURE', u'VER_COL_METH_CD',\n",
    "            u'VERT_ACCURACY_MSR', u'VERT_REF_DATUM_CD', u'ACTIVITY_STATUS_CD',u'WRTYPE',\n",
    "            u'WRLINK', u'SOURCE', u'VAL', u'CHEXNUM', u'TYPE', u'SUMMARY_ST', u'STATUS', u'PRIORITY',\n",
    "            u'USES', u'CFS', u'ACFT', u'LOCATION', u'WIN', u'WEB2']\n",
    "arcpy.DeleteField_management(stationname+'joins', droplist)\n",
    "fieldNames = [f.name for f in arcpy.ListFields(stationname+'joins')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:/GIS/WR_DATA.gdb\\\\SDWIS_Stats'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arcpy.AddXY_management(stationname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USGS Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute DeleteField to delete all fields in the field list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_rename = {u'TINWSF_IS_NUMBER':'site_no', u'UTV80_TINWSF_NAME':'station_nm', u'TINWSYS_IS_NUMBER':'system_no', \n",
    "              u'UTV80_TINWSYS_NAME':'system_nm', u'TYPE_CODE':'site_tp_cd', u'LAT_DMS_MSR':'lat_va', \n",
    "              u'LONG_DMS_MSR':'long_va', u'LATITUDE_MEASURE':'dec_lat_va', u'LONGITUDE_MEASURE':'dec_long_va', \n",
    "              u'HZ_COLLECT_METH_CD':'coord_meth_cd', u'HORIZ_ACCURACY_MSR':'coord_acy_cd', \n",
    "              u'HORIZ_REF_DATUM_CD':'coord_datum_cd', u'SOURCE_MAP_SCALE':'map_scale_fc', \n",
    "              u'VERTICAL_MEASURE':'alt_va', u'VER_COL_METH_CD':'alt_meth_cd', u'VERT_ACCURACY_MSR':'alt_acy_va', \n",
    "              u'VERT_REF_DATUM_CD':'alt_datum_cd',u'CONSTRUCTED_DATE':'construction_dt','ACTIVITY_STATUS_CD':'Status'}\n",
    "stations.rename(columns=col_rename,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://help.waterdata.usgs.gov/codes-and-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#siteTypes = pd.read_html('http://help.waterdata.usgs.gov/code/site_tp_query?fmt=html',match='Site Tp Cd',header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#county codes = http://www2.census.gov/geo/docs/reference/codes/files/st49_ut_cou.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st_type = {'WL':'GW','SP':'SP','IN':'FA-DV'}\n",
    "stations['site_tp_cd'] = stations['site_tp_cd'].apply(lambda x: st_type.get(x,x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vdatum = {1:'NAVD88',2:'NGVD88',3:'LMSL',4:'LMSL'}\n",
    "stations['alt_datum_cd'] = stations['alt_datum_cd'].apply(lambda x: vdatum.get(x,np.nan),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vmeth = {1:'D',2:'D',3:'D',4:'F',5:'D',6:'D',7:'L',9:'A',11:'L',10:'L',12:'L',13:'N',14:'M'}\n",
    "stations['alt_meth_cd'] = stations['alt_meth_cd'].apply(lambda x: vmeth.get(x,np.nan),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = {\"1\":500, \"2\":5000, \"3\":10000, \"4\":12000, \"5\":20000, \"6\":24000, \"7\":50000, \"8\":100000, \n",
    "         \"9\":100000, \"A\":10000, \"B\":12000, \"C\":15840, \"D\":20000, \"E\":24000, \"F\":25000, \"G\":50000,\n",
    "         \"H\":62500, \"I\":63360, \"J\":100000, \"K\":125000, \"L\":250000, \"M\":500000}\n",
    "stations.map_scale_fc = stations['map_scale_fc'].apply(lambda x: scale.get(x,np.nan),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdatum = {1:'NAD27',2:'NAD83',3:'WGS84'}\n",
    "stations.coord_datum_cd = stations['coord_datum_cd'].apply(lambda x: hdatum.get(x, np.nan),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def statproj(x):\n",
    "    ltd = x[0]\n",
    "    lng = x[1]\n",
    "    dat = x[2]\n",
    "    datdic = {1:'epsg:4267',2:'epsg:4269',3:'epsg:4326'}\n",
    "    p1 = Proj(init=datdic.get(x[2],'epsg:4269'))\n",
    "    p2 = Proj(proj='utm',zone=12,datum='NAD83')\n",
    "    if x[0] > 0 and abs(x[1]) > 0:\n",
    "        x1, y1 = pyproj.transform(p1, p2, lng, ltd)\n",
    "        return x1,y1\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "stations['UTMx'] = stations[['dec_lat_va','dec_long_va','coord_datum_cd']].apply(lambda x: statproj(x)[0],1)\n",
    "stations['UTMy'] = stations[['dec_lat_va','dec_long_va','coord_datum_cd']].apply(lambda x: statproj(x)[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mechanize\n",
    "def winmatch(x):\n",
    "    request = mechanize.Request(\"http://waterrights.utah.gov/wellinfo/wellsearch.asp\")\n",
    "    response = mechanize.urlopen(request)\n",
    "    forms = mechanize.ParseResponse(response, backwards_compat=False)\n",
    "    response.close()\n",
    "    form = forms[0] \n",
    "    #print form\n",
    "    form[\"mainoption\"]=[\"radius\"]\n",
    "    form[\"SearchRadius\"]=\"2000\"\n",
    "    form[\"option\"]=[\"UTM\"]\n",
    "    form[\"xUTM\"]=str(x[0])\n",
    "    form[\"yUTM\"]=str(x[1])\n",
    "    win =  mechanize.urlopen(form.click()).read()\n",
    "    winbeg = win.find('WIN=')\n",
    "    if winbeg == -1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        wintabeg=win.find('<table',win.find('<table')+5)\n",
    "        wintaend=win.find('</table>')\n",
    "        winmatches = pd.read_html(win[wintabeg:wintaend], header=0, skiprows=0)[0]\n",
    "        return winmatches.ix[0,'WIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations['nearWIN'] = stations[['UTMx','UTMy']].apply(lambda x: winmatch(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'C:/Users/PAULINKENBRANDT/AppData/Roaming/ESRI/Desktop10.4/ArcCatalog/AGRC_SGID.sde/SGID10.WATER.HUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Database Connections/SDWISAccess.odc/Stations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stations['sourceID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2csv2gdb(stations,fileloc,'C:/GIS/SDWISstations.csv','SDWISstations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://maps.waterrights.utah.gov/Downloads/wrpod.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
